{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":44224,"databundleVersionId":5188730,"sourceType":"competition"},{"sourceId":5148212,"sourceType":"datasetVersion","datasetId":2991134},{"sourceId":121796742,"sourceType":"kernelVersion"}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q timm pytorch-metric-learning\nimport os\nimport time\nimport random\nimport math\nimport copy\nimport cv2\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda import amp\n\nimport torch.multiprocessing as mp\nimport warnings\n\nimport pytorch_lightning as pl\nfrom torch.utils.data import DataLoader\nfrom sklearn import model_selection\nimport torchvision.transforms as transforms\nimport torchvision.io \nimport librosa\nfrom PIL import Image\nimport albumentations as alb\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score\n\nfrom tqdm.notebook import tqdm\nfrom collections import defaultdict\n\nimport timm\nfrom pytorch_metric_learning import losses\n\nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":6.667352,"end_time":"2022-04-22T06:00:08.901647","exception":false,"start_time":"2022-04-22T06:00:02.234295","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    model_name = \"skresnet18\"\n    img_size = 512\n    scheduler = 'CosineAnnealingLR'\n    use_mixup = True\n    mixup_alpha = 0.2   \n    T_max = 10\n    lr = 1e-5\n    min_lr = 1e-6\n    batch_size = 16\n    weight_decay = 1e-6\n    num_epochs = 10\n    num_classes = 264\n    embedding_size = 512\n    n_accumulate = 4\n    temperature = 0.1\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    data_root = \"/kaggle/input/birdclef-2023/\"\n    train_images = \"/kaggle/input/split-creating-melspecs-stage-1/specs/train/\"\n    valid_images = \"/kaggle/input/split-creating-melspecs-stage-1/specs/valid/\"\n    train_path = \"/kaggle/input/bc2023-train-val-df/train.csv\"\n    valid_path = \"/kaggle/input/bc2023-train-val-df/valid.csv\"\n    \n    \n    SR = 32000\n    DURATION = 5\n    MAX_READ_SAMPLES = 5\n    LR = 5e-4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 42):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    \n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CFG.seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(CFG.train_path)\ndf_valid = pd.read_csv(CFG.valid_path)\n\nlabel_encoder = LabelEncoder()\ntrain_labels = df_train['primary_label']\nlabel_encoder.fit(train_labels)\n\ndf_train['encoded_labels'] = label_encoder.transform(train_labels)\ndf_valid['encoded_labels'] = label_encoder.transform(df_valid['primary_label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BirdDataset(torch.utils.data.Dataset):\n\n    def __init__(self, df, sr = CFG.SR, duration = CFG.DURATION, transforms = None,  train = False):\n        self.df = df\n        self.sr = sr \n        self.train = train\n        self.duration = duration\n        self.transforms = transforms\n        if self.train:\n            self.img_dir = CFG.train_images\n        else:\n            self.img_dir = CFG.valid_images\n            \n    def __len__(self):\n        return len(self.df)\n\n    @staticmethod\n    def normalize(image):\n        image = image / 255.0\n        return image\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        impath = self.img_dir + f\"{row.filename}.npy\"\n        image = np.load(str(impath))[:CFG.MAX_READ_SAMPLES]\n        if self.train:\n            image = image[np.random.choice(len(image))]\n        else:\n            image = image[0]\n\n        if self.transforms:\n            image = self.transforms(image=image)[\"image\"]\n            \n        image = torch.tensor(image).float()\n        image = torch.stack([image, image, image])\n        image = self.normalize(image)\n        return image, torch.tensor(row.encoded_labels).float()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\ndata_transforms = {\n\n    \"train\": A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.OneOf([\n                A.Cutout(max_h_size=5, max_w_size=16),\n                A.CoarseDropout(max_holes=4),\n            ], p=0.5),\n    ]),\n    \"valid\": A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.OneOf([\n                A.Cutout(max_h_size=5, max_w_size=16),\n                A.CoarseDropout(max_holes=4),\n            ], p=0.5),\n    ])\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs, dataloaders, dataset_sizes, device, fold):\n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = np.inf\n    scaler = amp.GradScaler()\n\n    for step, epoch in enumerate(range(1,num_epochs+1)):\n        print('Epoch {}/{}'.format(epoch, num_epochs))\n        print('-' * 10)\n        for phase in ['train','valid']:\n            if(phase == 'train'):\n                model.train() \n            else:\n                model.eval() \n            \n            running_loss = 0.0\n            for inputs,labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(CFG.device)\n                labels = labels.to(CFG.device)\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    with amp.autocast(enabled=True):\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n                        loss = loss / CFG.n_accumulate\n                    \n                    if phase == 'train':\n                        scaler.scale(loss).backward()\n\n                    if phase == 'train' and (step + 1) % CFG.n_accumulate == 0:\n                        scaler.step(optimizer)\n                        scaler.update()\n                        scheduler.step()\n                        optimizer.zero_grad()\n                running_loss += loss.item()*inputs.size(0)\n            \n            epoch_loss = running_loss/dataset_sizes[phase]            \n\n            print('{} Loss: {:.4f}'.format(\n                phase, epoch_loss))\n            \n            # deep copy the model\n            if phase=='valid' and epoch_loss <= best_loss:\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n                PATH = f\"Fold{fold}_{best_loss}_epoch_{epoch}.bin\"\n                torch.save(model.state_dict(), PATH)\n        print()\n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best Loss \",best_loss)\n\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_fold(model, criterion, optimizer, scheduler, device, fold, num_epochs=10):\n    \n    train_data = BirdDataset(\n        df_train, \n        sr = CFG.SR,\n        duration = CFG.DURATION,\n        transforms = data_transforms[\"train\"],\n        train = True\n    )\n        \n    valid_data = BirdDataset(\n        df_valid, \n        sr = CFG.SR,\n        duration = CFG.DURATION,\n        transforms = data_transforms[\"valid\"],\n    )\n    \n    dataset_sizes = {\n        'train' : len(train_data),\n        'valid' : len(valid_data)\n    }\n    \n    train_loader = DataLoader(dataset=train_data, batch_size=CFG.batch_size, num_workers=4, pin_memory=True, shuffle=True)\n    valid_loader = DataLoader(dataset=valid_data, batch_size=CFG.batch_size, num_workers=4, pin_memory=True, shuffle=False)\n    \n    dataloaders = {\n        'train' : train_loader,\n        'valid' : valid_loader\n    }\n\n    model = train_model(model, criterion, optimizer, scheduler, num_epochs, dataloaders, dataset_sizes, device, fold)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = timm.create_model(CFG.model_name, pretrained=True)\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features, CFG.embedding_size)\nmodel.to(CFG.device)\nprint(\"Model loaded\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SupervisedContrastiveLoss(nn.Module):\n    def __init__(self, temperature=0.1):\n        super(SupervisedContrastiveLoss, self).__init__()\n        self.temperature = temperature\n\n    def forward(self, feature_vectors, labels):\n        feature_vectors_normalized = F.normalize(feature_vectors, p=2, dim=1)\n        logits = torch.div( torch.matmul( feature_vectors_normalized, torch.transpose(feature_vectors_normalized, 0, 1) ), self.temperature)\n        return losses.NTXentLoss(temperature=0.07)(logits, torch.squeeze(labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = SupervisedContrastiveLoss(temperature=CFG.temperature).to(CFG.device) \noptimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr)\nmodel = run_fold(model, criterion, optimizer, scheduler, device=CFG.device, fold=0, num_epochs=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fc = nn.Linear(in_features=512, out_features=CFG.num_classes, bias=True)\ntorch.save({ 'model_state_dict': model.state_dict(),}, 'sk_with_contrastive_loss.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}