{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":44224,"databundleVersionId":5188730,"sourceType":"competition"},{"sourceId":5148212,"sourceType":"datasetVersion","datasetId":2991134},{"sourceId":7158251,"sourceType":"datasetVersion","datasetId":4134164},{"sourceId":121796742,"sourceType":"kernelVersion"}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q torchtoolbox timm\n!pip install -q pytorch_metric_learning\n\nimport os\nimport time\nimport random\nimport math\nimport copy\nimport cv2\nimport sklearn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc \n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda import amp\n\nimport torch.multiprocessing as mp\nimport warnings\n\nfrom torchtoolbox.tools import mixup_data, mixup_criterion\nfrom torch.nn.functional import cross_entropy\nimport torchmetrics\nimport timm\n\nimport pytorch_lightning as pl\nfrom torch.utils.data import DataLoader\nfrom sklearn import model_selection\nimport torchvision.transforms as transforms\nimport torchvision.io \nimport librosa\nfrom PIL import Image\nimport albumentations as alb\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom pytorch_lightning.callbacks import ModelCheckpoint, BackboneFinetuning, EarlyStopping\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau, OneCycleLR\n\nfrom tqdm.notebook import tqdm\nfrom collections import defaultdict\n\nimport timm\nfrom pytorch_metric_learning import losses\n\nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":6.667352,"end_time":"2022-04-22T06:00:08.901647","exception":false,"start_time":"2022-04-22T06:00:02.234295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-09T07:08:01.982194Z","iopub.execute_input":"2023-12-09T07:08:01.983026Z","iopub.status.idle":"2023-12-09T07:08:25.712608Z","shell.execute_reply.started":"2023-12-09T07:08:01.982988Z","shell.execute_reply":"2023-12-09T07:08:25.711256Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"class Config:\n    num_classes = 264\n    batch_size = 64\n    epochs = 10  \n    seed = 2023\n    model = \"skresnet18\"\n    pretrained = True            \n    weight_decay = 1e-3\n    use_mixup = True\n    mixup_alpha = 0.2   \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n    data_root = \"/kaggle/input/birdclef-2023/\"\n    train_images = \"/kaggle/input/split-creating-melspecs-stage-1/specs/train/\"\n    valid_images = \"/kaggle/input/split-creating-melspecs-stage-1/specs/valid/\"\n    train_path = \"/kaggle/input/bc2023-train-val-df/train.csv\"\n    valid_path = \"/kaggle/input/bc2023-train-val-df/valid.csv\"\n    sampling_rate = 32000\n    signal_duration = 5\n    learning_rate = 5e-4\n    \npl.seed_everything(Config.seed, workers=True)","metadata":{"papermill":{"duration":0.099568,"end_time":"2022-04-22T06:00:18.542447","exception":false,"start_time":"2022-04-22T06:00:18.442879","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-09T07:08:25.715529Z","iopub.execute_input":"2023-12-09T07:08:25.716478Z","iopub.status.idle":"2023-12-09T07:08:25.727837Z","shell.execute_reply.started":"2023-12-09T07:08:25.716424Z","shell.execute_reply":"2023-12-09T07:08:25.726698Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"2023"},"metadata":{}}]},{"cell_type":"code","source":"df_train = pd.read_csv(Config.train_path)\ndf_valid = pd.read_csv(Config.valid_path)\ndf_train = pd.concat([df_train, pd.get_dummies(df_train['primary_label'])], axis=1)\ndf_valid = pd.concat([df_valid, pd.get_dummies(df_valid['primary_label'])], axis=1)\nbirds = list(df_train.primary_label.unique())\nmissing_birds = list(set(list(df_train.primary_label.unique())).difference(list(df_valid.primary_label.unique())))\nnon_missing_birds = list(set(list(df_train.primary_label.unique())).difference(missing_birds))\ndf_valid[missing_birds] = 0\ndf_valid = df_valid[df_train.columns] ","metadata":{"papermill":{"duration":58.466679,"end_time":"2022-04-22T06:01:17.158088","exception":false,"start_time":"2022-04-22T06:00:18.691409","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-09T07:08:25.729259Z","iopub.execute_input":"2023-12-09T07:08:25.729607Z","iopub.status.idle":"2023-12-09T07:08:25.872692Z","shell.execute_reply.started":"2023-12-09T07:08:25.729577Z","shell.execute_reply":"2023-12-09T07:08:25.871799Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_train_transform():\n    return A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.OneOf([\n                A.Cutout(max_h_size=5, max_w_size=16),\n                A.CoarseDropout(max_holes=4),\n            ], p=0.5),\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:08:25.875280Z","iopub.execute_input":"2023-12-09T07:08:25.875562Z","iopub.status.idle":"2023-12-09T07:08:25.881437Z","shell.execute_reply.started":"2023-12-09T07:08:25.875534Z","shell.execute_reply":"2023-12-09T07:08:25.880434Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n\n    def __init__(self, df, sr = Config.sampling_rate, duration = Config.signal_duration, augmentations = None, train = True):\n\n        self.df = df\n        self.sr = sr \n        self.train = train\n        self.duration = duration\n        self.augmentations = augmentations\n        if train:\n            self.img_dir = Config.train_images\n        else:\n            self.img_dir = Config.valid_images\n\n    def __len__(self):\n        return len(self.df)\n\n    @staticmethod\n    def normalize(image):\n        image = image / 255.0\n        return image\n\n    def __getitem__(self, idx):\n\n        row = self.df.iloc[idx]\n        impath = self.img_dir + f\"{row.filename}.npy\"\n        image = np.load(str(impath))[:5]        \n        if self.train:\n            image = image[np.random.choice(len(image))]\n        else:\n            image = image[0]\n            \n        image = torch.tensor(image).float()\n        if self.augmentations:\n            image = self.augmentations(image.unsqueeze(0)).squeeze()\n        \n        image = torch.stack([image, image, image])\n        image = self.normalize(image)\n        return image, torch.tensor(row[17:]).float()\n","metadata":{"papermill":{"duration":0.039034,"end_time":"2022-04-22T06:01:17.350173","exception":false,"start_time":"2022-04-22T06:01:17.311139","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-09T07:08:25.882889Z","iopub.execute_input":"2023-12-09T07:08:25.883748Z","iopub.status.idle":"2023-12-09T07:08:25.895858Z","shell.execute_reply.started":"2023-12-09T07:08:25.883716Z","shell.execute_reply":"2023-12-09T07:08:25.894879Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def load_dataset(df_train, df_valid):\n\n    ds_train = Dataset(\n        df_train, \n        sr = Config.sampling_rate,\n        duration = Config.signal_duration,\n        augmentations = None,\n        train = True\n    )\n    \n    ds_val = Dataset(\n        df_valid, \n        sr = Config.sampling_rate,\n        duration = Config.signal_duration,\n        augmentations = None,\n        train = False\n    )\n    dl_train = DataLoader(ds_train, batch_size=Config.batch_size , shuffle=True, num_workers = 2)    \n    dl_val = DataLoader(ds_val, batch_size=Config.batch_size, num_workers = 2)\n    return dl_train, dl_val, ds_train, ds_val","metadata":{"papermill":{"duration":0.036289,"end_time":"2022-04-22T06:01:17.539606","exception":false,"start_time":"2022-04-22T06:01:17.503317","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-09T07:08:25.897171Z","iopub.execute_input":"2023-12-09T07:08:25.897486Z","iopub.status.idle":"2023-12-09T07:08:25.910435Z","shell.execute_reply.started":"2023-12-09T07:08:25.897457Z","shell.execute_reply":"2023-12-09T07:08:25.909395Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def get_optimizer(lr, params):\n    model_optimizer = torch.optim.Adam(\n            filter(lambda p: p.requires_grad, params), \n            lr=lr,\n            weight_decay=Config.weight_decay\n        )\n    interval = \"epoch\"\n    \n    lr_scheduler = CosineAnnealingWarmRestarts(\n                            model_optimizer, \n                            T_0=Config.epochs, \n                            T_mult=1, \n                            eta_min=1e-6, \n                            last_epoch=-1\n                        )\n\n    return {\n        \"optimizer\": model_optimizer, \n        \"lr_scheduler\": {\n            \"scheduler\": lr_scheduler,\n            \"interval\": interval,\n            \"monitor\": \"val_loss\",\n            \"frequency\": 1\n        }\n    }","metadata":{"papermill":{"duration":0.048043,"end_time":"2022-04-22T06:01:22.109544","exception":false,"start_time":"2022-04-22T06:01:22.061501","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-09T07:08:25.911884Z","iopub.execute_input":"2023-12-09T07:08:25.912367Z","iopub.status.idle":"2023-12-09T07:08:25.923313Z","shell.execute_reply.started":"2023-12-09T07:08:25.912327Z","shell.execute_reply":"2023-12-09T07:08:25.922294Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def padded_cmap(solution, submission, padding_factor=5):\n    solution = solution\n    submission = submission\n    new_rows = []\n    for i in range(padding_factor):\n        new_rows.append([1 for i in range(len(solution.columns))])\n    new_rows = pd.DataFrame(new_rows)\n    new_rows.columns = solution.columns\n    padded_solution = pd.concat([solution, new_rows]).reset_index(drop=True).copy()\n    padded_submission = pd.concat([submission, new_rows]).reset_index(drop=True).copy()\n    score = sklearn.metrics.average_precision_score(\n        padded_solution.values,\n        padded_submission.values,\n        average='macro',\n    )\n    return score\n\ndef map_score(solution, submission):\n    solution = solution\n    submission = submission\n    score = sklearn.metrics.average_precision_score(\n        solution.values,\n        submission.values,\n        average='micro',\n    )\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:08:25.924677Z","iopub.execute_input":"2023-12-09T07:08:25.925285Z","iopub.status.idle":"2023-12-09T07:08:25.938009Z","shell.execute_reply.started":"2023-12-09T07:08:25.925246Z","shell.execute_reply":"2023-12-09T07:08:25.937066Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class Model(pl.LightningModule):\n    def __init__(self, model_name=Config.model, num_classes = Config.num_classes, pretrained = Config.pretrained):\n        super().__init__()\n        self.num_classes = num_classes\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        self.in_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Linear(self.in_features, num_classes)\n        checkpoint = torch.load('/kaggle/input/model-weights/sk_with_contrastive_loss.pth')\n        self.backbone.load_state_dict(checkpoint['model_state_dict'])\n        self.loss_function = nn.BCEWithLogitsLoss() \n\n    def forward(self,images):\n        logits = self.backbone(images)\n        return logits\n        \n    def configure_optimizers(self):\n        return get_optimizer(lr=Config.learning_rate, params=self.parameters())\n\n    def train_with_mixup(self, X, y):\n        X, y_a, y_b, lam = mixup_data(X, y, alpha=Config.mixup_alpha)\n        y_pred = self(X)\n        loss_mixup = mixup_criterion(cross_entropy, y_pred, y_a, y_b, lam)\n        return loss_mixup\n\n    def training_step(self, batch, batch_idx):\n        image, target = batch        \n        if Config.use_mixup:\n            loss = self.train_with_mixup(image, target)\n        else:\n            y_pred = self(image)\n            loss = self.loss_function(y_pred,target)\n\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n        return loss        \n\n    def validation_step(self, batch, batch_idx):\n        image, target = batch     \n        y_pred = self(image)\n        val_loss = self.loss_function(y_pred, target)\n        self.log(\"val_loss\", val_loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)    \n        return {\"val_loss\": val_loss, \"logits\": y_pred, \"targets\": target}\n    \n    def train_dataloader(self):\n        return self._train_dataloader \n    \n    def validation_dataloader(self):\n        return self._validation_dataloader\n    \n    def validation_epoch_end(self,outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        output_val = torch.cat([x['logits'] for x in outputs],dim=0).sigmoid().cpu().detach().numpy()\n        target_val = torch.cat([x['targets'] for x in outputs],dim=0).cpu().detach().numpy()\n        \n        val_df = pd.DataFrame(target_val, columns = birds)\n        pred_df = pd.DataFrame(output_val, columns = birds)        \n        avg_score = padded_cmap(val_df, pred_df, padding_factor = 5)\n               \n        print(f'epoch {self.current_epoch} validation loss {avg_loss}')\n        print(f'epoch {self.current_epoch} validation C-MAP score pad 5 {avg_score}')\n        \n        return {'val_loss': avg_loss,'val_cmap':avg_score}","metadata":{"papermill":{"duration":0.156714,"end_time":"2022-04-22T06:01:22.301564","exception":false,"start_time":"2022-04-22T06:01:22.14485","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-09T07:08:25.939151Z","iopub.execute_input":"2023-12-09T07:08:25.939424Z","iopub.status.idle":"2023-12-09T07:08:25.959234Z","shell.execute_reply.started":"2023-12-09T07:08:25.939396Z","shell.execute_reply":"2023-12-09T07:08:25.958227Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def run_training():\n    print(f\"Running training...\")    \n    dl_train, dl_val, ds_train, ds_val = load_dataset(df_train, df_valid)\n    \n    audio_model = Model()\n    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=8, verbose= True, mode=\"min\")\n    checkpoint_callback = ModelCheckpoint(monitor='val_loss',\n                                          dirpath= \"/kaggle/working/exp1/\",\n                                      save_top_k=1,\n                                      save_last= True,\n                                      save_weights_only=True,\n                                      filename= f'./{Config.model}_loss',\n                                      verbose= True,\n                                      mode='min')\n    \n    callbacks_to_use = [checkpoint_callback,early_stop_callback]\n\n\n    trainer = pl.Trainer(\n        gpus=1,\n        val_check_interval=0.5,\n        deterministic=True,\n        max_epochs=10,\n        auto_lr_find=False,    \n        callbacks=callbacks_to_use,\n        precision=16, accelerator=\"gpu\" \n    )\n\n    print(\"Running trainer.fit\")\n    trainer.fit(audio_model, train_dataloaders = dl_train, val_dataloaders = dl_val)                \n\n    gc.collect()\n    torch.cuda.empty_cache()\n    return audio_model","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:08:25.962822Z","iopub.execute_input":"2023-12-09T07:08:25.963295Z","iopub.status.idle":"2023-12-09T07:08:25.974833Z","shell.execute_reply.started":"2023-12-09T07:08:25.963255Z","shell.execute_reply":"2023-12-09T07:08:25.973874Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model = run_training()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:08:25.976220Z","iopub.execute_input":"2023-12-09T07:08:25.977057Z","iopub.status.idle":"2023-12-09T07:09:57.751584Z","shell.execute_reply.started":"2023-12-09T07:08:25.977025Z","shell.execute_reply":"2023-12-09T07:09:57.750621Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Running training...\nRunning trainer.fit\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"epoch 0 validation loss 0.7384665012359619\nepoch 0 validation C-MAP score pad 5 0.9408054506012066\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3398beb3cb7948b487701d7ee148d8cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"epoch 0 validation loss 0.2426360845565796\nepoch 0 validation C-MAP score pad 5 0.6018534500288357\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"epoch 0 validation loss 0.16977612674236298\nepoch 0 validation C-MAP score pad 5 0.6668877056731761\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save({'model_state_dict': model.backbone.state_dict() }, 'skresnet18_with_contrastive loss.pth')","metadata":{"execution":{"iopub.status.busy":"2023-12-09T03:37:44.116243Z","iopub.execute_input":"2023-12-09T03:37:44.117362Z","iopub.status.idle":"2023-12-09T03:37:44.187872Z","shell.execute_reply.started":"2023-12-09T03:37:44.117309Z","shell.execute_reply":"2023-12-09T03:37:44.186780Z"},"trusted":true},"execution_count":null,"outputs":[]}]}